import codecs
import datetime
import subprocess
import sys
import time
import os

from django.core import exceptions
from django.conf import settings
from django.db import transaction

from apps.process_monitor.sipproc import SipProcess
from apps.base_item import models as base_item

import models

try:
    TREE_IS_INGESTION_SVN = settings.TREE_IS_INGESTION_SVN
except:
    TREE_IS_INGESTION_SVN = False



IMPORT_SCAN_TREE = settings.IMPORT_SCAN_TREE


AUTOGEN_NAME = 'Autogenerated by Sip Manager'


class RequestCreate(SipProcess):
    SHORT_DESCRIPTION = 'Scan for new imports, if found grab it'
    PROVIDER_TYPE_LOOKUP = {'L': models.PROVT_LIBRARY,
                            'A':models.PROVT_ARCHIVE,
                            'M': models.PROVT_MUSEUM,
                            'AA': models.PROVT_AUDIO_VIS_ARCH,
                            'AG': models.PROVT_AGGREGATOR,
                            }

    def __init__(self, *args, **kwargs):
        self.skip_dirs = ['error', 'to-import', 'to-import-cache-only',
                          'to-import-no-cache', 'uploading', '.svn']
        super(RequestCreate, self).__init__(*args, **kwargs)

    def run_it(self):
        """
        Dirs to be scanned:
            finished
            imported
            importing
            nonexistent
            uploaded
            validated
            validating

        Indicating a deletion:
            error

        Avoid the following:
            to-import
            to-import-cache-only
            to-import-no-cache
            uploading
        """
        skip_trees = [] # if we find a subtree that shouldnt be followed like .svn dont dive into it
        for dirpath, dirnames, filenames in os.walk(IMPORT_SCAN_TREE):
            if dirpath == IMPORT_SCAN_TREE:
                continue
            b = False
            for bad_tree in skip_trees:
                if bad_tree in dirpath:
                    b = True
                    break
            if b:
                continue

            # avoid specific relative dirs that shouldnt be traversed
            if os.path.split(dirpath)[-1] in self.skip_dirs:
                skip_trees.append(dirpath)
                continue

            # if we are scanning the ingestion svn only /.../output_xml/ should be used
            if TREE_IS_INGESTION_SVN and os.path.split(dirpath)[-1] != 'output_xml':
                continue

            for filename in filenames:
                if os.path.splitext(filename)[1] != '.xml':
                    continue
                # if we are scanning the ingestion svn avoid things like 'dddd.sample.xml'
                if TREE_IS_INGESTION_SVN and os.path.splitext(os.path.splitext(filename)[0])[1] != '':
                    # extra check needed for using ingestion svn tree
                    continue

                # we (hopefully) have a relevant file, check if it is already ingested
                data_sets = models.DataSet.objects.filter(name_code=filename)
                if data_sets:
                    data_set = data_sets[0]
                else:
                    # in normal operation we should propably abort here,
                    # Datasets should propably be pre-created by ingestion
                    data_set = self.add_data_set(filename)
                    if not data_set:
                        continue # wasnt a valid dataset

                full_path = os.path.join(dirpath, filename)
                mtime = os.path.getmtime(full_path)
                time_created = datetime.datetime.fromtimestamp(mtime)
                requests = models.Request.objects.filter(data_set=data_set,
                                                         time_created=time_created,
                                                         file_name=filename)
                if not requests:
                    # only add new requests
                    record_count = self.record_count(full_path)
                    request = models.Request().add_from_file(data_set, full_path, record_count)
                    self.log('Added request %s' % filename, 3)
                pass
        return True

    def add_data_set(self, file_name):
        try:
            int(file_name[:5]) # we use it as string but check that it is an int...
        except:
            return None # not a valid dataset

        aggregator_nc = file_name[:2]
        aggregators = models.Aggregator.objects.filter(name_code=aggregator_nc)
        if aggregators:
            aggregator = aggregators[0]
        else:
            aggregator = models.Aggregator(name_code=aggregator_nc, name=AUTOGEN_NAME)
            aggregator.save()

        provider_nc = file_name[2:5]
        providers = models.Provider.objects.filter(name_code=provider_nc)
        if providers:
            provider = providers[0]
        else:
            try:
                sanitized_file_name = os.path.splitext(file_name)[0].replace('__','_')
                s = sanitized_file_name.split('_')[1].upper()
                item_type = self.PROVIDER_TYPE_LOOKUP[s]
                country_idx = 2
            except:
                item_type = 1
                country_idx= 1
            try:
                country = sanitized_file_name.split('_')[country_idx]
                if len(country) > 2:
                    raise
            except:
                country = '??'
            try:
                name = ' '.join(sanitized_file_name.split('_')[country_idx+1:])
            except:
                name = AUTOGEN_NAME
            provider = models.Provider(aggregator=aggregator,
                                       name_code=provider_nc,
                                       name=name,
                                       item_type=item_type,
                                       country=country)
            provider.save()

        data_sets = models.DataSet.objects.filter(name_code=file_name)
        if data_sets:
            data_set = data_sets[0]
        else:
            data_set = models.DataSet(provider=provider,
                                      name_code=file_name,
                                      name=AUTOGEN_NAME,
                                      language='??')
            data_set.save()

        return data_set

    def record_count(self, fname):
        #cmd = "awk 'BEGIN {RS=FS}{if ( $0 ~ /<record>/ ) c++} END{print c}' %s" % fname
        cmd = 'awk -F "<record>" \'{s+=(NF-1)} END {print s}\' %s' % fname
        self.log('counting records in %s' % fname, 9)
        p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE,
                             stderr=subprocess.PIPE, close_fds=True)
        retcode = p.wait()
        if retcode:
            self.abort_process('shell command counting records in xml-file failed: %s' % fname)
        rec_count = p.stdout.read().strip() or 0
        self.log('\tfound records: %s' % rec_count, 9)
        return rec_count



class RequestParseNew(SipProcess):
    """
    hash for a MdRecord
    """
    SHORT_DESCRIPTION = 'Parse new processes'

    def run_it(self):
        """
        for mdRecord in MdRecord.items.all():
            if not Uri.items.filter(md_rec_id=mdRecord.id):
                u = Uri(md_rec_id=mdRecord.id)
                u.save()
        """
        while True:
            requests = models.Request.objects.filter(status=models.REQS_PRE,
                                                    pid=0)
            if not requests:
                break
            self.handle_request(requests[0])
        return True

    @transaction.commit_manually
    def handle_request(self, request):
        full_path = self.find_file(request)
        if not full_path:
            self.error_log('Cant find file %s for Request %i' % (
                request.file_name, request.pk))
            return True
        request = self.grab_item(models.Request, request.pk,
                                 'About to parse for ese records')
        if not request:
            return True

        self.current_request = request
        self.log('Parsing ese file for records: %s' % full_path, 1)
        #f = codecs.open(full_path, 'r', 'utf-8')
        f = open(full_path, 'r')
        record_count = 0
        record = []
        self.task_starting('Reading ESE records from file',request.record_count)
        line = f.readline()[:-1].strip() # skip lf and other pre/post whitespace
        t0 = time.time()
        while line:
            if line == '<record>':
                record = []
                record_count += 1
            elif line == '</record>':
                #self.add_record(record)
                lst = record[:] # sort a copy dont touch org
                lst.sort()
                r_hash = base_item.calculate_mdr_content_hash('\n'.join(lst))
                mdrs = base_item.MdRecord.objects.filter(content_hash=r_hash)
                if mdrs:
                    mdr= mdrs[0]
                else:
                    # MdRecord not found, create a new
                    mdr = base_item.MdRecord(content_hash=r_hash,source_data='\n'.join(record))
                    mdr.save()
                r_m = base_item.RequestMdRecord(request=self.current_request,
                                                 md_record=mdr)
                r_m.save()
            elif line: # skip empty lines
                record.append(line)
            if t0 + self.TASK_PROGRESS_TIME < time.time():
                self.task_progress(record_count)
                t0 = time.time()
                transaction.commit()
            line = f.readline()[:-1].strip() # skip lf and other pre/post whitespace
        f.close()
        request.status = models.REQS_INIT
        request.save()
        self.release_item(models.Request, request.pk)
        transaction.commit()
        return True


    def add_record(self, record):
        lst = record[:] # sort a copy dont touch org
        lst.sort()
        r_hash = base_item.calculate_mdr_content_hash('\n'.join(lst))
        mdrs = base_item.MdRecord.objects.filter(content_hash=r_hash)
        if mdrs:
            mdr= mdrs[0]
        else:
            # MdRecord not found, create a new
            mdr = base_item.MdRecord(content_hash=r_hash,source_data='\n'.join(record))
            mdr.save()
        r_m = base_item.RequestMdRecord(request=self.current_request,
                                         md_record=mdr)
        r_m.save()

    def find_file(self, request):
        ret = ''
        found = False
        for dirpath, dirnames, filenames in os.walk(IMPORT_SCAN_TREE):
            if found:
                break
            for filename in filenames:
                if filename == request.file_name:
                    full_path = os.path.join(dirpath, filename)
                    mtime = os.path.getmtime(full_path)
                    time_created = datetime.datetime.fromtimestamp(mtime)
                    if request.time_created == time_created:
                        found = True
                        ret = full_path
                        break
                    pass
            pass
        return ret




task_list = [RequestCreate,
             RequestParseNew
             ]
