import sys
import os
import datetime

from django.core import exceptions
from django.conf import settings

from utils.sipproc import SipProcess

import models

try:
    TREE_IS_INGESTION_SVN = settings.TREE_IS_INGESTION_SVN
except:
    TREE_IS_INGESTION_SVN = False

try:
    IMPORT_SCAN_TREE = settings.IMPORT_SCAN_TREE
except:
    raise exceptions.ImproperlyConfigured('Missing setting IMPORT_SCAN_TREE')

AUTOGEN_NAME = 'Autogenerated by Sip Manager'

class RequestParseNew(SipProcess):
    SHORT_DESCRIPTION = 'Parse new processes'

    def run_it(self):
        """
        for mdRecord in MdRecord.items.all():
            if not Uri.items.filter(md_rec_id=mdRecord.id):
                u = Uri(md_rec_id=mdRecord.id)
                u.save()
        """
        requests = models.Request.objects.filter(status=models.REQS_INIT,
                                                 pid=0)
        if not requests:
            return True # no pending requests
        for request in requests:
            if not request.pid:
                self.handle_request(requests[0])
        return True

    def handle_request(self, request):
        full_path = self.find_file(request)
        if not full_path:
            self.error_log('Cant find file %s for Request %i' % (
                request.file_name, request.pk))
            return False
        request = self.grab_item(models.Request, request.pk)
        if not request:
            return False
        x = WgetFileParser(request, debug_lvl=4)
        x.run()
        return True



    def find_file(self, request):
        full_path = ''
        found = False
        for dirpath, dirnames, filenames in os.walk(IMPORT_SCAN_TREE):
            if found:
                break
            for filename in filenames:
                if filename == request.file_name:
                    full_path = os.path.join(dirpath, filename)
                    mtime = os.path.getmtime(full_path)
                    time_created = datetime.datetime.fromtimestamp(mtime)
                    if request.time_created == time_created:
                        found = True
                        break
                    pass
            pass
        return full_path




class RequestFindNew(SipProcess):
    SHORT_DESCRIPTION = 'Scan for new imports, if found grab it'
    PROVIDER_TYPE_LOOKUP = {'L': models.PROVT_LIBRARY,
                            'A':models.PROVT_ARCHIVE,
                            'M': models.PROVT_MUSEUM,
                            'AA': models.PROVT_AUDIO_VIS_ARCH,
                            'AG': models.PROVT_AGGREGATOR,
                            }

    def __init__(self, *args, **kwargs):
        self.skip_dirs = ['error', 'to-import', 'to-import-cache-only',
                          'to-import-no-cache', 'uploading', '.svn']
        super(RequestFindNew, self).__init__(*args, **kwargs)

    def run_it(self):
        """
        Dirs to be scanned:
            finished
            imported
            importing
            nonexistent
            uploaded
            validated
            validating

        Indicating a deletion:
            error

        Avoid the following:
            to-import
            to-import-cache-only
            to-import-no-cache
            uploading
        """
        skip_trees = [] # if we find a subtree that shouldnt be followed like .svn dont dive into it
        for dirpath, dirnames, filenames in os.walk(IMPORT_SCAN_TREE):
            if dirpath == IMPORT_SCAN_TREE:
                continue
            b = False
            for bad_tree in skip_trees:
                if bad_tree in dirpath:
                    b = True
                    break
            if b:
                continue

            # avoid specific relative dirs that shouldnt be traversed
            if os.path.split(dirpath)[-1] in self.skip_dirs:
                skip_trees.append(dirpath)
                continue

            # if we are scanning the ingestion svn only /.../output_xml/ should be used
            if TREE_IS_INGESTION_SVN and os.path.split(dirpath)[-1] != 'output_xml':
                continue

            for filename in filenames:
                if os.path.splitext(filename)[1] != '.xml':
                    continue
                # if we are scanning the ingestion svn avoid things like 'dddd.sample.xml'
                if TREE_IS_INGESTION_SVN and os.path.splitext(os.path.splitext(filename)[0])[1] != '':
                    # extra check needed for using ingestion svn tree
                    continue

                # we (hopefully) have a relevant file, check if it is already ingested
                data_sets = models.DataSet.objects.filter(name_code=filename)
                if data_sets:
                    data_set = data_sets[0]
                else:
                    # in normal operation we should propably abort here,
                    # Datasets should propably be pre-created by ingestion
                    data_set = self.add_data_set(filename)
                    if not data_set:
                        continue # wasnt a valid dataset

                full_path = os.path.join(dirpath, filename)
                mtime = os.path.getmtime(full_path)
                time_created = datetime.datetime.fromtimestamp(mtime)
                requests = models.Request.objects.filter(data_set_id=data_set,
                                                         time_created=time_created,
                                                         file_name=filename)
                if not requests:
                    # only add new requests
                    request = models.Request().add_from_file(data_set, full_path)
                    self.log('Added request %s' % filename)
                pass
        return True

    def add_data_set(self, file_name):
        try:
            int(file_name[:5]) # we use it as string but check that it is an int...
        except:
            return None # not a valid dataset

        aggregator_nc = file_name[:2]
        aggregators = models.Aggregator.objects.filter(name_code=aggregator_nc)
        if aggregators:
            aggregator = aggregators[0]
        else:
            aggregator = models.Aggregator(name_code=aggregator_nc, name=AUTOGEN_NAME)
            aggregator.save()

        provider_nc = file_name[2:5]
        providers = models.Provider.objects.filter(name_code=provider_nc)
        if providers:
            provider = providers[0]
        else:
            try:
                sanitized_file_name = os.path.splitext(file_name)[0].replace('__','_')
                s = sanitized_file_name.split('_')[1].upper()
                item_type = self.PROVIDER_TYPE_LOOKUP[s]
                country_idx = 2
            except:
                item_type = 1
                country_idx= 1
            try:
                country = sanitized_file_name.split('_')[country_idx]
                if len(country) > 2:
                    raise
            except:
                country = '??'
            try:
                name = ' '.join(sanitized_file_name.split('_')[country_idx+1:])
            except:
                name = AUTOGEN_NAME
            provider = models.Provider(aggregator_id=aggregator,
                                       name_code=provider_nc,
                                       name=name,
                                       item_type=item_type,
                                       country=country)
            provider.save()

        data_sets = models.DataSet.objects.filter(name_code=file_name)
        if data_sets:
            data_set = data_sets[0]
        else:
            data_set = models.DataSet(provider_id=provider,
                                      name_code=file_name,
                                      name=AUTOGEN_NAME,
                                      language='??')
            data_set.save()

        return data_set


task_list = [RequestParseNew, RequestFindNew]
